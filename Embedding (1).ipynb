{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjAZYReJB57v",
        "outputId": "c7fab0fb-e0aa-4f6c-dd41-15412bd539d1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔤 What is Embedding?\n",
        "\n",
        "\n",
        "Embedding is a technique used to convert high-dimensional or symbolic data (like words, images, or items) into a low-dimensional vector (a list of numbers). These vectors capture semantic or structural meaning of the original data, and they are used as input to machine learning models, especially in Natural Language Processing (NLP) and Recommendation Systems"
      ],
      "metadata": {
        "id": "H8iqQ-jQCJU8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "💡 Why Use Embeddings?\n",
        "\n",
        "\n",
        "Because:\n",
        "\n",
        "Machines don’t understand text or images directly.\n",
        "\n",
        "They need numerical representations.\n",
        "\n",
        "Embeddings help capture relationships and similarities."
      ],
      "metadata": {
        "id": "lWvGE2K7Cz8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Input text"
      ],
      "metadata": {
        "id": "usQAJXqUDJnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "\n",
        "text = \"I am Ashvinkumar bari working on AI Eng Position\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oFs9TSkuCEv2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Load tokenizer and model (we'll use BERT as an example)"
      ],
      "metadata": {
        "id": "GudALDnHDMyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n"
      ],
      "metadata": {
        "id": "rJ7okjESDDi4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Tokenization"
      ],
      "metadata": {
        "id": "mqAZP9HPDPIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "tokens = tokenizer.tokenize(text)\n",
        "print(\"🔹 Tokens:\", tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywbSEzQGDHA7",
        "outputId": "a04786c3-74af-4821-aae4-c6dffb88cc70"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Tokens: ['i', 'am', 'ash', '##vin', '##kumar', 'bari', 'working', 'on', 'ai', 'eng', 'position']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Step 4: Convert tokens to token IDs"
      ],
      "metadata": {
        "id": "CAVRyxNjDX3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(\"🔹 Token IDs:\", token_ids)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCKh5LjcDUdt",
        "outputId": "622fff9e-9b28-401c-f469-dcdf3cf07cb1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Token IDs: [1045, 2572, 6683, 6371, 18494, 22466, 2551, 2006, 9932, 25540, 2597]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Step 5: Convert token IDs to input tensor"
      ],
      "metadata": {
        "id": "RTEspnZ8Dh5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(text, return_tensors=\"pt\")  # automatically adds special tokens like [CLS] and [SEP]\n",
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGPENsNdDlS2",
        "outputId": "ea6fea65-cf09-4139-ee9c-9cf2cb2d45e2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  1045,  2572,  6683,  6371, 18494, 22466,  2551,  2006,  9932,\n",
            "         25540,  2597,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Generate embeddings from the model"
      ],
      "metadata": {
        "id": "ObBIrlHWDrFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "#print(outputs)"
      ],
      "metadata": {
        "id": "kSSeEpfIDsMv"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Extract embeddings (from the last hidden state)"
      ],
      "metadata": {
        "id": "9Bw2OnlND4cQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Shape: [batch_size, sequence_length, embedding_dimension]\n",
        "embeddings = outputs.last_hidden_state\n",
        "\n",
        "print(\"🔹 Embeddings shape:\", embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTZPd9OBDxd2",
        "outputId": "118a49d9-feb7-4cf5-84b7-c1163a3e3018"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Embeddings shape: torch.Size([1, 13, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Optional: View embeddings of each token"
      ],
      "metadata": {
        "id": "8g26BgL1EJ8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for token, embedding_vector in zip(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0]), embeddings[0]):\n",
        "    print(f\"{token:10s} → Embedding vector shape: {embeddings.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuU7lm0mEHth",
        "outputId": "2173533e-3101-42e0-ffcd-fb5705af1bf2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]      → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "i          → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "am         → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "ash        → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "##vin      → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "##kumar    → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "bari       → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "working    → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "on         → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "ai         → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "eng        → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "position   → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "[SEP]      → Embedding vector shape: torch.Size([1, 13, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optional: View embeddings of each token"
      ],
      "metadata": {
        "id": "ZTe6bj6cEx3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for token, embedding_vector in zip(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0]), embeddings[0]):\n",
        "    print(f\"{token:10s} → Embedding vector shape: {embeddings.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYs5lP1PEROs",
        "outputId": "892fed0e-fa12-46b0-9ac4-e4a6115fa6af"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]      → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "i          → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "am         → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "ash        → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "##vin      → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "##kumar    → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "bari       → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "working    → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "on         → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "ai         → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "eng        → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "position   → Embedding vector shape: torch.Size([1, 13, 768])\n",
            "[SEP]      → Embedding vector shape: torch.Size([1, 13, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for token, embedding_vector in zip(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0]), embeddings[0]):\n",
        "    print(f\"{token:10s} → Embedding vector shape: {embeddings}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uW_sQRlEzGb",
        "outputId": "989a7e10-da20-4498-d0c0-b0e941434d7e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]      → Embedding vector shape: tensor([[[-0.3441,  0.2321,  0.1651,  ..., -0.3527,  0.4396,  0.2655],\n",
            "         [ 0.6251, -0.3805, -0.5655,  ..., -0.1628,  0.9383,  0.1508],\n",
            "         [ 0.2569,  0.1752,  0.3612,  ..., -0.0098,  0.5865,  0.4507],\n",
            "         ...,\n",
            "         [-0.2569,  0.0353,  0.4537,  ..., -0.7675,  0.2623, -0.4840],\n",
            "         [-0.2360, -0.2788,  0.0153,  ...,  0.3330,  0.2637, -0.3080],\n",
            "         [ 0.7282, -0.0205, -0.1759,  ...,  0.2141, -0.5070, -0.3118]]])\n",
            "i          → Embedding vector shape: tensor([[[-0.3441,  0.2321,  0.1651,  ..., -0.3527,  0.4396,  0.2655],\n",
            "         [ 0.6251, -0.3805, -0.5655,  ..., -0.1628,  0.9383,  0.1508],\n",
            "         [ 0.2569,  0.1752,  0.3612,  ..., -0.0098,  0.5865,  0.4507],\n",
            "         ...,\n",
            "         [-0.2569,  0.0353,  0.4537,  ..., -0.7675,  0.2623, -0.4840],\n",
            "         [-0.2360, -0.2788,  0.0153,  ...,  0.3330,  0.2637, -0.3080],\n",
            "         [ 0.7282, -0.0205, -0.1759,  ...,  0.2141, -0.5070, -0.3118]]])\n",
            "am         → Embedding vector shape: tensor([[[-0.3441,  0.2321,  0.1651,  ..., -0.3527,  0.4396,  0.2655],\n",
            "         [ 0.6251, -0.3805, -0.5655,  ..., -0.1628,  0.9383,  0.1508],\n",
            "         [ 0.2569,  0.1752,  0.3612,  ..., -0.0098,  0.5865,  0.4507],\n",
            "         ...,\n",
            "         [-0.2569,  0.0353,  0.4537,  ..., -0.7675,  0.2623, -0.4840],\n",
            "         [-0.2360, -0.2788,  0.0153,  ...,  0.3330,  0.2637, -0.3080],\n",
            "         [ 0.7282, -0.0205, -0.1759,  ...,  0.2141, -0.5070, -0.3118]]])\n",
            "ash        → Embedding vector shape: tensor([[[-0.3441,  0.2321,  0.1651,  ..., -0.3527,  0.4396,  0.2655],\n",
            "         [ 0.6251, -0.3805, -0.5655,  ..., -0.1628,  0.9383,  0.1508],\n",
            "         [ 0.2569,  0.1752,  0.3612,  ..., -0.0098,  0.5865,  0.4507],\n",
            "         ...,\n",
            "         [-0.2569,  0.0353,  0.4537,  ..., -0.7675,  0.2623, -0.4840],\n",
            "         [-0.2360, -0.2788,  0.0153,  ...,  0.3330,  0.2637, -0.3080],\n",
            "         [ 0.7282, -0.0205, -0.1759,  ...,  0.2141, -0.5070, -0.3118]]])\n",
            "##vin      → Embedding vector shape: tensor([[[-0.3441,  0.2321,  0.1651,  ..., -0.3527,  0.4396,  0.2655],\n",
            "         [ 0.6251, -0.3805, -0.5655,  ..., -0.1628,  0.9383,  0.1508],\n",
            "         [ 0.2569,  0.1752,  0.3612,  ..., -0.0098,  0.5865,  0.4507],\n",
            "         ...,\n",
            "         [-0.2569,  0.0353,  0.4537,  ..., -0.7675,  0.2623, -0.4840],\n",
            "         [-0.2360, -0.2788,  0.0153,  ...,  0.3330,  0.2637, -0.3080],\n",
            "         [ 0.7282, -0.0205, -0.1759,  ...,  0.2141, -0.5070, -0.3118]]])\n",
            "##kumar    → Embedding vector shape: tensor([[[-0.3441,  0.2321,  0.1651,  ..., -0.3527,  0.4396,  0.2655],\n",
            "         [ 0.6251, -0.3805, -0.5655,  ..., -0.1628,  0.9383,  0.1508],\n",
            "         [ 0.2569,  0.1752,  0.3612,  ..., -0.0098,  0.5865,  0.4507],\n",
            "         ...,\n",
            "         [-0.2569,  0.0353,  0.4537,  ..., -0.7675,  0.2623, -0.4840],\n",
            "         [-0.2360, -0.2788,  0.0153,  ...,  0.3330,  0.2637, -0.3080],\n",
            "         [ 0.7282, -0.0205, -0.1759,  ...,  0.2141, -0.5070, -0.3118]]])\n",
            "bari       → Embedding vector shape: tensor([[[-0.3441,  0.2321,  0.1651,  ..., -0.3527,  0.4396,  0.2655],\n",
            "         [ 0.6251, -0.3805, -0.5655,  ..., -0.1628,  0.9383,  0.1508],\n",
            "         [ 0.2569,  0.1752,  0.3612,  ..., -0.0098,  0.5865,  0.4507],\n",
            "         ...,\n",
            "         [-0.2569,  0.0353,  0.4537,  ..., -0.7675,  0.2623, -0.4840],\n",
            "         [-0.2360, -0.2788,  0.0153,  ...,  0.3330,  0.2637, -0.3080],\n",
            "         [ 0.7282, -0.0205, -0.1759,  ...,  0.2141, -0.5070, -0.3118]]])\n",
            "working    → Embedding vector shape: tensor([[[-0.3441,  0.2321,  0.1651,  ..., -0.3527,  0.4396,  0.2655],\n",
            "         [ 0.6251, -0.3805, -0.5655,  ..., -0.1628,  0.9383,  0.1508],\n",
            "         [ 0.2569,  0.1752,  0.3612,  ..., -0.0098,  0.5865,  0.4507],\n",
            "         ...,\n",
            "         [-0.2569,  0.0353,  0.4537,  ..., -0.7675,  0.2623, -0.4840],\n",
            "         [-0.2360, -0.2788,  0.0153,  ...,  0.3330,  0.2637, -0.3080],\n",
            "         [ 0.7282, -0.0205, -0.1759,  ...,  0.2141, -0.5070, -0.3118]]])\n",
            "on         → Embedding vector shape: tensor([[[-0.3441,  0.2321,  0.1651,  ..., -0.3527,  0.4396,  0.2655],\n",
            "         [ 0.6251, -0.3805, -0.5655,  ..., -0.1628,  0.9383,  0.1508],\n",
            "         [ 0.2569,  0.1752,  0.3612,  ..., -0.0098,  0.5865,  0.4507],\n",
            "         ...,\n",
            "         [-0.2569,  0.0353,  0.4537,  ..., -0.7675,  0.2623, -0.4840],\n",
            "         [-0.2360, -0.2788,  0.0153,  ...,  0.3330,  0.2637, -0.3080],\n",
            "         [ 0.7282, -0.0205, -0.1759,  ...,  0.2141, -0.5070, -0.3118]]])\n",
            "ai         → Embedding vector shape: tensor([[[-0.3441,  0.2321,  0.1651,  ..., -0.3527,  0.4396,  0.2655],\n",
            "         [ 0.6251, -0.3805, -0.5655,  ..., -0.1628,  0.9383,  0.1508],\n",
            "         [ 0.2569,  0.1752,  0.3612,  ..., -0.0098,  0.5865,  0.4507],\n",
            "         ...,\n",
            "         [-0.2569,  0.0353,  0.4537,  ..., -0.7675,  0.2623, -0.4840],\n",
            "         [-0.2360, -0.2788,  0.0153,  ...,  0.3330,  0.2637, -0.3080],\n",
            "         [ 0.7282, -0.0205, -0.1759,  ...,  0.2141, -0.5070, -0.3118]]])\n",
            "eng        → Embedding vector shape: tensor([[[-0.3441,  0.2321,  0.1651,  ..., -0.3527,  0.4396,  0.2655],\n",
            "         [ 0.6251, -0.3805, -0.5655,  ..., -0.1628,  0.9383,  0.1508],\n",
            "         [ 0.2569,  0.1752,  0.3612,  ..., -0.0098,  0.5865,  0.4507],\n",
            "         ...,\n",
            "         [-0.2569,  0.0353,  0.4537,  ..., -0.7675,  0.2623, -0.4840],\n",
            "         [-0.2360, -0.2788,  0.0153,  ...,  0.3330,  0.2637, -0.3080],\n",
            "         [ 0.7282, -0.0205, -0.1759,  ...,  0.2141, -0.5070, -0.3118]]])\n",
            "position   → Embedding vector shape: tensor([[[-0.3441,  0.2321,  0.1651,  ..., -0.3527,  0.4396,  0.2655],\n",
            "         [ 0.6251, -0.3805, -0.5655,  ..., -0.1628,  0.9383,  0.1508],\n",
            "         [ 0.2569,  0.1752,  0.3612,  ..., -0.0098,  0.5865,  0.4507],\n",
            "         ...,\n",
            "         [-0.2569,  0.0353,  0.4537,  ..., -0.7675,  0.2623, -0.4840],\n",
            "         [-0.2360, -0.2788,  0.0153,  ...,  0.3330,  0.2637, -0.3080],\n",
            "         [ 0.7282, -0.0205, -0.1759,  ...,  0.2141, -0.5070, -0.3118]]])\n",
            "[SEP]      → Embedding vector shape: tensor([[[-0.3441,  0.2321,  0.1651,  ..., -0.3527,  0.4396,  0.2655],\n",
            "         [ 0.6251, -0.3805, -0.5655,  ..., -0.1628,  0.9383,  0.1508],\n",
            "         [ 0.2569,  0.1752,  0.3612,  ..., -0.0098,  0.5865,  0.4507],\n",
            "         ...,\n",
            "         [-0.2569,  0.0353,  0.4537,  ..., -0.7675,  0.2623, -0.4840],\n",
            "         [-0.2360, -0.2788,  0.0153,  ...,  0.3330,  0.2637, -0.3080],\n",
            "         [ 0.7282, -0.0205, -0.1759,  ...,  0.2141, -0.5070, -0.3118]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Input text\n",
        "text = \"Ashvin  is a Eng\"\n",
        "\n",
        "# Tokenize and convert to tensor\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "# Forward pass to get embeddings\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Extract embeddings (last hidden state)\n",
        "# Shape: [1, sequence_length, embedding_dim]\n",
        "embeddings = outputs.last_hidden_state\n",
        "\n",
        "# Optional: Convert to one sentence vector by averaging token embeddings (excluding [CLS] and [SEP])\n",
        "sentence_embedding = embeddings[0][1:-1].mean(dim=0)\n",
        "\n",
        "print(\"🔹 Sentence embedding shape:\", sentence_embedding.shape)\n",
        "print(\"🔹 Sentence embedding (first 5 values):\", sentence_embedding[:20])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQyXydXmE7Jl",
        "outputId": "1e482cc9-375f-4089-8fe5-a4ec97407ee5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Sentence embedding shape: torch.Size([768])\n",
            "🔹 Sentence embedding (first 5 values): tensor([ 0.0643, -0.0413, -0.1851, -0.4175,  0.3276, -0.4492,  0.1968,  0.3278,\n",
            "        -0.2401,  0.2177,  0.0584, -0.0746, -0.1477,  0.7629,  0.7641, -0.3194,\n",
            "         0.2162,  0.1506, -0.1022,  0.3476])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GK-UySrIFwGC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}